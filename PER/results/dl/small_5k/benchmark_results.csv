model_name,train_accuracy,train_f1,test_accuracy,test_f1,test_precision,test_recall,overfit_gap,train_time_sec,inference_time_ms,memory_mb,num_parameters,pct_tokens_lost,pct_samples_truncated
BERT,0.824,0.8239655158338164,0.8053333333333333,0.8053388705578942,0.8055276782158503,0.8053333333333333,0.01866666666666661,174.9163463115692,4.0161549250284825,802.99609375,109.483778,0.0,0.0
DistilBERT,0.836,0.8360082473849756,0.7946666666666666,0.7946316071551379,0.7946983241283759,0.7946666666666666,0.04133333333333333,94.49294471740723,2.095681508382161,158.078125,66.95501,0.0,0.0
RoBERTa,0.8254285714285714,0.8254018390368756,0.7973333333333333,0.7972612227954693,0.7974729344729344,0.7973333333333333,0.028095238095238062,186.0747058391571,3.9997933705647783,212.625,124.64717,0.0,0.0
