model_name,train_accuracy,train_f1,test_accuracy,test_f1,test_precision,test_recall,overfit_gap,train_time_sec,inference_time_ms,memory_mb,num_parameters,pct_tokens_lost,pct_samples_truncated
BERT,0.8098571428571428,0.8098569682360626,0.7973333333333333,0.7973275684286131,0.7973671671087911,0.7973333333333333,0.012523809523809493,350.3264436721802,3.9202246665954594,1836.50390625,109.483778,69.58516000154209,69.9
DistilBERT,0.8091428571428572,0.809138884125277,0.7933333333333333,0.7933241477398996,0.7933854907539118,0.7933333333333333,0.01580952380952383,368.0240807533264,4.014791329701742,1851.86328125,66.95501,69.58516000154209,69.9
RoBERTa,0.795,0.7944099762349447,0.792,0.7914066678552326,0.795360546664269,0.792,0.0030000000000000027,728.0129296779633,3.935869852701823,629.0390625,124.64717,69.58516000154209,69.9
